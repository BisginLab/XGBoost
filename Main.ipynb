{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from statistics import mean\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classifiers = [1]\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "output = []\n",
    "\n",
    "# mergedfeatures1 = pd.read_csv('mergedfeaturessep102.csv')\n",
    "mergedfeatures1 = pd.read_csv('corrected_permacts.csv')\n",
    "\n",
    "# mergedfeatures = mergedfeatures1[['pkgname', 'lowest_android_version', 'highest_android_version', 'paid', 'file_size', 'max_downloads_log',\n",
    "# 'developer_email', 'privacy_policy_link', 'developer_address', 'developer_website', 'days_since_last_update',\n",
    "# 'DevRegisteredDomain', 'LenDescription', 'LenWhatsNew', 'ReviewsAverage', 'CurrentVersion',\n",
    "# 'Genre', 'ContentRating', 'LastUpdated', 'LenTitle', 'AndroidVersion', 'DeveloperCategory', 'isSpamming',\n",
    "# 'net', 'intent', 'bluetooth', 'app', 'provider', 'speech', 'nfc', 'media', 'hardware', 'google',\n",
    "# 'os', 'CALENDAR', 'CAMERA', 'CONTACTS', 'LOCATION', 'MICROPHONE', 'PHONE', 'SENSORS',\n",
    "# 'SMS', 'STORAGE', 'FourStarRatings', 'ThreeStarRatings', 'FiveStarRatings', 'OneStarRatings',\n",
    "# 'TwoStarRatings', 'status']]\n",
    "# mergedfeatures[\"FourStarRatings\"] = mergedfeatures[\"FourStarRatings\"].fillna(0)\n",
    "# mergedfeatures[\"ThreeStarRatings\"] = mergedfeatures[\"ThreeStarRatings\"].fillna(0)\n",
    "# mergedfeatures[\"FiveStarRatings\"] = mergedfeatures[\"FiveStarRatings\"].fillna(0)\n",
    "# mergedfeatures[\"OneStarRatings\"] = mergedfeatures[\"OneStarRatings\"].fillna(0)\n",
    "# mergedfeatures[\"TwoStarRatings\"] = mergedfeatures[\"TwoStarRatings\"].fillna(0)\n",
    "\n",
    "mergedfeatures = mergedfeatures1[['pkgname', 'lowest_android_version', 'highest_android_version', 'paid', 'file_size',\n",
    "'developer_email', 'privacy_policy_link', 'developer_address', 'developer_website',\n",
    "'DevRegisteredDomain', 'LenDescription', 'CurrentVersion',\n",
    "'Genre', 'ContentRating','LenTitle', 'AndroidVersion', 'DeveloperCategory', 'isSpamming',\n",
    "'net', 'intent', 'bluetooth', 'app', 'provider', 'speech', 'nfc', 'media', 'hardware', 'google',\n",
    "'os', 'CALENDAR', 'CAMERA', 'CONTACTS', 'LOCATION', 'MICROPHONE', 'PHONE', 'SENSORS',\n",
    "'SMS', 'STORAGE', 'status']]\n",
    "\n",
    "\n",
    "mergedfeatures = mergedfeatures.drop(['pkgname'], axis=1, inplace=False)\n",
    "def encode_and_bind(original_dataframe, feature_to_encode):\n",
    "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
    "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "    res = res.drop([feature_to_encode], axis=1)\n",
    "    return(res) \n",
    "\n",
    "features_to_encode = ['lowest_android_version', 'highest_android_version', 'CurrentVersion',\n",
    "                      'Genre', 'ContentRating', 'AndroidVersion', 'DeveloperCategory']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedfeatures = encode_and_bind(mergedfeatures, features_to_encode[0])\n",
    "mergedfeatures = encode_and_bind(mergedfeatures, features_to_encode[1])\n",
    "mergedfeatures = encode_and_bind(mergedfeatures, features_to_encode[2])\n",
    "mergedfeatures = encode_and_bind(mergedfeatures, features_to_encode[3])\n",
    "mergedfeatures = encode_and_bind(mergedfeatures, features_to_encode[4])\n",
    "mergedfeatures = encode_and_bind(mergedfeatures, features_to_encode[5])\n",
    "mergedfeatures = encode_and_bind(mergedfeatures, features_to_encode[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full - Train dataset: (609359, 2391)\n",
      "Full - Test dataset: (261155, 2391)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(mergedfeatures, test_size=0.3, stratify=mergedfeatures.status)\n",
    "output.append(\"Full - Train dataset: \" + str(train.shape))\n",
    "print(\"Full - Train dataset: \" + str(train.shape))\n",
    "output.append(\"Full - Test dataset: \" + str(test.shape))\n",
    "print(\"Full - Test dataset: \" + str(test.shape))\n",
    "\n",
    "#this method would help us select a balanced dataset of size k\n",
    "def sampling_k_elements(group, k=50000):\n",
    "    if len(group) < k:\n",
    "        return group\n",
    "    return group.sample(k)\n",
    "\n",
    "#defininging and initilizing a number of lists to store the XGBoostClassifiers \n",
    "#and the random parameters\n",
    "estimators_list = [256,512]\n",
    "depths_list = [2,3]\n",
    "\n",
    "#trying out different number of classifiers 1-15\n",
    "# num_classifiers = [i for i in range(11,13, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full - Trying 1 classifiers......\n"
     ]
    }
   ],
   "source": [
    "#initialize the n classifiers with randomally selected parameters\n",
    "# for n in num_classifiers:\n",
    "output.append(\"Full - Trying \" + str(num_classifiers[0]) +  \" classifiers......\")\n",
    "print(\"Full - Trying \" + str(num_classifiers[0]) +  \" classifiers......\")\n",
    "classifiers_list = []\n",
    "for c in range(num_classifiers[0]):\n",
    "  nest = random.choice(estimators_list)\n",
    "  mxd = random.choice(depths_list)\n",
    "  classifier=XGBClassifier(n_estimators=nest, max_depth=mxd)\n",
    "  classifiers_list.append(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full - Balanced dataset: (100000, 2391)\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers_list:\n",
    "  #train the classifiers on balanced datasets drawn from the training dataset\n",
    "  pos = train[train['status'] == 1].sample(50000, replace = False)\n",
    "  neg = train[train['status'] == 0].sample(50000, replace = False)\n",
    "  # balanced_set = pos.append(neg)\n",
    "  balanced_set = pd.concat([pos, neg])\n",
    "  #balanced_set = train.groupby('status').apply(sampling_k_elements).reset_index(drop=True)\n",
    "  output.append(\"Full - Balanced dataset: \" + str(balanced_set.shape))\n",
    "  print(\"Full - Balanced dataset: \" + str(balanced_set.shape))\n",
    "  #X,y = balanced_set.iloc[:, :-1], balanced_set.iloc[:, -1]\n",
    "  y = balanced_set['status'].values\n",
    "  X = balanced_set.drop(['status'],axis=1,inplace=False).values\n",
    "  classifier.fit(X,y)\n",
    "#print(\"classifier\", classifiers_list.index(classifier), \"   :\", classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full - Validation dataset: (261111, 2391)\n"
     ]
    }
   ],
   "source": [
    "# draw a new sample from the training dataset, while maintaining the original \n",
    "# class distribution, validation dataset, same size like test dataset\n",
    "# test2 is validation set, X2 is validation as well\n",
    "train_2 , test_2 = train_test_split(train, test_size=0.4285, stratify=train.status)\n",
    "output.append(\"Full - Validation dataset: \" + str(test_2.shape))\n",
    "print(\"Full - Validation dataset: \" + str(test_2.shape))\n",
    "y2 = test_2['status'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 261111 entries, 69788 to 629437\n",
      "Columns: 2391 entries, paid to DeveloperCategory_Moderate\n",
      "dtypes: bool(2360), int64(31)\n",
      "memory usage: 651.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(test_2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = test_2.drop(['status'],axis=1,inplace=False).values\n",
    "#print(\"X2 shape: \", X2.shape)\n",
    "#print(\"y2 shape: \", y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = X2.shape[0]\n",
    "target = np.zeros((size,2))\n",
    "size2 = len(mergedfeatures.columns)-1\n",
    "importaccum = np.zeros(size2)\n",
    "#size = X2.shape[0]\n",
    "#print(\"size : \" , size)\n",
    "#target = [0.0]*size\n",
    "for clasfier in classifiers_list:\n",
    "  preds = clasfier.predict_proba(X2)\n",
    "  target = np.add(target, preds) \n",
    "  #preds = clasfier.predict(X2)\n",
    "  #print(\"Before: target[1]:\", target[1])\n",
    "  #target = [target[i] + preds[i] for i in range(len(target))]\n",
    "  #print(\"After: target[1]:\", target[1])\n",
    "  #plot important features\n",
    "  importances = clasfier.feature_importances_\n",
    "  importaccum = np.add(importaccum,importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = mergedfeatures.columns\n",
    "importaccum2 = importaccum / len(classifiers_list)\n",
    "indices = np.argsort(importaccum2)\n",
    "  # customized number \n",
    "num_features = 20\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title('Feature Importances')\n",
    "# only plot the customized number of features\n",
    "plt.barh(range(num_features), importaccum2[indices[-num_features:]], color='b', align='center')\n",
    "plt.yticks(range(num_features), [features[i] for i in indices[-num_features:]])\n",
    "plt.xlabel('Relative Importance')\n",
    "pltname = str(len(classifiers_list)) + \"-classifiers-Evaluation-Full\"\n",
    "#plt.savefig(\"%s.png\" % pltname, dpi=300) #2400x1800 pixels instead of 800x600, try 600\n",
    "#   plt.savefig(\"%s.pdf\" % pltname, dpi=800)\n",
    "# plt.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full - Evaluation AUC: 0.757\n"
     ]
    }
   ],
   "source": [
    "#target2 = [target[i]/len(classifiers_list) for i in range(len(target))]\n",
    "target2 = target / len(classifiers_list)\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y2, target2[:,1])\n",
    "output.append('Full - Evaluation AUC: %.3f' % auc)\n",
    "print('Full - Evaluation AUC: %.3f' % auc)\n",
    "\n",
    "# fpr means false-positive-rate\n",
    "# tpr means true-positive-rate\n",
    "fpr, tpr, _ = metrics.roc_curve(y2, target2[:,1])\n",
    "auc_score = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# get tp, fp, tn, fn for validation dataset\n",
    "indices_fp = (y2 == 0) & (np.round(target2[:,1]) == 1)\n",
    "indices_fn = (y2 == 1) & (np.round(target2[:,1]) == 0)\n",
    "indices_tp = (y2 == 1) & (np.round(target2[:,1]) == 1)\n",
    "indices_tn = (y2 == 0) & (np.round(target2[:,1]) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = test['status'].values\n",
    "X3 = test.drop(['status'],axis=1,inplace=False).values\n",
    "\n",
    "size2 = X3.shape[0]\n",
    "target1 = np.zeros((size2,2))\n",
    "for clasfier in classifiers_list:\n",
    "  preds2 = clasfier.predict_proba(X3)\n",
    "  target1 = np.add(target1, preds2) \n",
    "\n",
    "target3 = target1 / len(classifiers_list)\n",
    "# calculate AUC\n",
    "auc2 = roc_auc_score(y3, target3[:,1])\n",
    "output.append('Full - Testing AUC: %.3f' % auc2)\n",
    "print('Full - Testing AUC: %.3f' % auc2)\n",
    "\n",
    "# fpr means false-positive-rate\n",
    "# tpr means true-positive-rate\n",
    "fpr2, tpr2, _ = metrics.roc_curve(y3, target3[:,1])\n",
    "auc_score2 = metrics.auc(fpr2, tpr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tp, fp, tn, fn for test dataset\n",
    "indices_fp_test = (y3 == 0) & (np.round(target1[:,1]) == 1)\n",
    "indices_fn_test = (y3 == 1) & (np.round(target1[:,1]) == 0)\n",
    "indices_tp_test = (y3 == 1) & (np.round(target1[:,1]) == 1)\n",
    "indices_tn_test = (y3 == 0) & (np.round(target1[:,1]) == 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
